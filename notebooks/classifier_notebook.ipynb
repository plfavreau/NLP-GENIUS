{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ce notebook est dédié au classifier (Lyrics to genre) du projet NLP.\n",
        "Commençons par importer les différents packages"
      ],
      "metadata": {
        "id": "pRyZzcTPUQ1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iVWgPQFOHgW",
        "outputId": "c1742934-afbe-4428-b6d8-9a3267354792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcAYt-NFI28R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tiktoken\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite vous aurez besoin de récupérer le dataset en provenance de kaggle.\n",
        "Pour se faire, je vous prie de suivre ce tuto\n",
        "https://www.kaggle.com/discussions/general/74235#2580958\n"
      ],
      "metadata": {
        "id": "jDdVUSw_UgJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "!kaggle datasets download -d carlosgdcj/genius-song-lyrics-with-language-information\n",
        "!unzip genius-song-lyrics-with-language-information.zip"
      ],
      "metadata": {
        "id": "MDC8kI5JtYRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c4da34-d196-4db1-cec1-ce01da2c8cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading genius-song-lyrics-with-language-information.zip to /content\n",
            "100% 3.04G/3.04G [01:18<00:00, 41.6MB/s]\n",
            "100% 3.04G/3.04G [01:18<00:00, 41.7MB/s]\n",
            "Archive:  genius-song-lyrics-with-language-information.zip\n",
            "  inflating: song_lyrics.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etape de préprocessing 'rapide'."
      ],
      "metadata": {
        "id": "eSHPqMCKVK_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5FMy0qwI5IF",
        "outputId": "f8be2aa2-e663-441f-e11d-c05bf58a01cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=51348, step=1)\n"
          ]
        }
      ],
      "source": [
        "# n = 100 every 100th line = 1% of the lines 50 000 lines taken\n",
        "df = pd.read_csv(\"song_lyrics.csv\", skiprows=lambda i: i % 100 != 0)\n",
        "print(df.index)\n",
        "df = df[df['tag'] != 'misc']\n",
        "if 'language' in df.columns:\n",
        "    df = df[df['language'] == 'en']\n",
        "df = df[['title', 'lyrics', 'tag']]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "# To shuffle randomnly datas\n",
        "df = df.sample(frac = 1)\n",
        "# Split the data into features (X) and labels (Y)\n",
        "X = df['lyrics']\n",
        "Y = df['tag']\n",
        "\n",
        "# Split the data into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisons les tokenizers vu en cours encore une fois dans un soucis de rapidité"
      ],
      "metadata": {
        "id": "ZtysXMjoVWoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK8H-lVxa2k_"
      },
      "outputs": [],
      "source": [
        "#Define tokenizers from course\n",
        "def lemma_tokenize(doc):\n",
        "    wnl = WordNetLemmatizer()\n",
        "    return [wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
        "\n",
        "def char_tokenize(doc):\n",
        "    return [char for char in doc]\n",
        "\n",
        "def byte_tokenize(doc):\n",
        "    tokens = doc.encode(\"utf-8\")\n",
        "    tokens = list(map(int, tokens))\n",
        "    return [str(token) for token in tokens]\n",
        "\n",
        "def gpt_tokenize(doc):\n",
        "    enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    tokens = enc.encode(doc)\n",
        "    return [str(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création du classifier en utilisant scikit-learn\n",
        "On peut s'amuser à jouer sur les différents paramètres et hyperparamètres pour voir si on obtient de meilleur résultats"
      ],
      "metadata": {
        "id": "JvOYfNa1Venh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6WEHzZM3F3R"
      },
      "outputs": [],
      "source": [
        "# Create model, we can test them one by one or even customize them using hyperparameters tunning\n",
        "model = make_pipeline(CountVectorizer(ngram_range = (1,1), stop_words = en_stop), MultinomialNB()) #Naive Bayes\n",
        "#model = make_pipeline(CountVectorizer(ngram_range = (1,1), stop_words = en_stop), LogisticRegression()) #Logistic Regression\n",
        "model.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On évalue dans un premier temps le modèle simplement en regardant sa précision."
      ],
      "metadata": {
        "id": "3rY8evECVyx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.score(X_test, Y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "Dc620KYbVxLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce-dessous une liste de toutes les combinaisons qui ont été testées une par une. Pour obtenir une vue des résultats : voir l'annexe dans le repo github."
      ],
      "metadata": {
        "id": "UfcIoe5mXJaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = make_pipeline(CountVectorizer(tokenizer=gpt_tokenize, ngram_range=(1, 1)), scaler, LogisticRegression( max_iter = 1000, solver='saga',penalty='l2'))\n",
        "#model = make_pipeline(CountVectorizer(tokenizer=byte_tokenize, ngram_range=(1, 1)), scaler, LogisticRegression( max_iter = 1000, solver='saga',penalty='l2'))\n",
        "#model = make_pipeline(CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 1)), scaler, LogisticRegression( max_iter = 1000, solver='saga',penalty='l2'))\n",
        "#model = make_pipeline(CountVectorizer(ngram_range=(1, 1), scaler, LogisticRegression( max_iter = 3000, solver='lbfgs'))\n",
        "#model = make_pipeline(CountVectorizer(ngram_range=(1, 2), scaler, LogisticRegression( max_iter = 3000, solver='lbfgs'))\n",
        "\n",
        "\n",
        "#model = make_pipeline(CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 1)), scaler, LogisticRegression( max_iter = 1000, solver='saga',penalty='elasticnet', l1-ratio=0.5))\n"
      ],
      "metadata": {
        "id": "jFJtJ4OeWEg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici comment évaluer le modèle de manière plus pertinente.\n",
        "On se permet d'utiliser\n",
        "\n",
        "*   La matrice de confusion\n",
        "*   Le classification report fourni par sk-learn\n",
        "*   L'évaluation empirique\n",
        "\n",
        "Matrice de confusion : on voit précisément où le modèle s'est trompé / où il a bien prédit\n",
        "\n"
      ],
      "metadata": {
        "id": "ETSGehw5YplL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(Y_test, Y_pred_classes))\n",
        "cm = confusion_matrix(Y_test, Y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yKtlyCMRZdN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification report : qu'on envoit vers un fichier excel pour ensuite le comparer avec d'autres itérations"
      ],
      "metadata": {
        "id": "HQ7g8ojeZnuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
        "# Convert classification report to dictionary\n",
        "report_dict = classification_report(Y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df_excel = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Convert the DataFrame to Excel format\n",
        "df_excel.to_excel(\"classification_report.xlsx\")"
      ],
      "metadata": {
        "id": "bo1B4wR_ZlfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests empirique 'visuels' : on prend au hasard certaines musiques.\n",
        "Et on regarde si notre modèle performe bien dessus ou pas.\n",
        "Enfin on affiche les erreurs/réussites"
      ],
      "metadata": {
        "id": "qYBfC3e_ZuZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"song_lyrics.csv\", skiprows=lambda i: i % 977 != 0 , nrows=10) # Change here to test different values\n",
        "\n",
        "df_test = df_test[df_test['tag'] != 'misc']\n",
        "if 'language' in df_test.columns:\n",
        "    df_test = df_test[df_test['language'] == 'en']\n",
        "df_test = df_test[['title', 'lyrics', 'tag']]\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for song_name, song_lyrics, song_tag in zip(df_test['title'], df_test['lyrics'], df_test['tag']):\n",
        "    print(\"Song:\", song_name)\n",
        "    print(\"Tag:\", song_tag)\n",
        "    # Convert the lyrics to a list and predict probabilities\n",
        "    probabilities = model.predict_proba([song_lyrics])\n",
        "\n",
        "    # Print the distribution of probabilities\n",
        "    print(\"Distribution of Probabilities:\")\n",
        "    for class_label, probability in zip(model.classes_, probabilities[0]):\n",
        "        if(probability > 0.0001):\n",
        "          print(f\"{class_label}: {probability:.4f}\")\n",
        "    max_prob_index = probabilities.argmax()\n",
        "    predicted_class = model.classes_[max_prob_index]\n",
        "    if predicted_class != song_tag:\n",
        "        print(f'Model failed to predict. Actual tag is {song_tag}, predicted tag is {predicted_class}')\n",
        "    print()"
      ],
      "metadata": {
        "id": "DOMoRncdYp_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans une optique de performance nous avons décidé de voir ce si les perfomances étaient meilleures sans utiliser scikit-learn\n",
        "\n",
        "Passons donc maintenant à l'implementation du classifer à l'aide de PyTorch."
      ],
      "metadata": {
        "id": "EGihQ2xWV3DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "TjxcYIZs1gVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "Y_train_vec = vectorizer.fit_transform(Y_train)\n",
        "Y_test_vec = vectorizer.transform(Y_test)"
      ],
      "metadata": {
        "id": "liEEQOpb1A0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_vec.toarray(), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_vec.toarray(), dtype=torch.float32)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_indices = label_encoder.fit_transform(Y_train)\n",
        "Y_test_indices = label_encoder.transform(Y_test)\n",
        "\n",
        "Y_train_tensor = torch.tensor(Y_train_indices, dtype=torch.long)\n",
        "Y_test_tensor = torch.tensor(Y_test_indices, dtype=torch.long)"
      ],
      "metadata": {
        "id": "JNxBk6Bk1CcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTDiq8kEplVV"
      },
      "outputs": [],
      "source": [
        "# Define logistic regression model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "input_size = X_train_tensor.shape[1]\n",
        "num_classes = len(Y_train.unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On utilise la CrossEntropy Loss et l'optimizer Adam"
      ],
      "metadata": {
        "id": "5DuddfuGYUnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = LogisticRegression(input_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "6U07jIJ61J8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tensor.shape)\n",
        "print(X_test_tensor.shape)\n",
        "print(Y_train_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8z60Vy-73-h",
        "outputId": "f8dd7fbe-05a8-45a1-e927-ad5fab4e156c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25680, 79784])\n",
            "torch.Size([6420, 79784])\n",
            "torch.Size([25680])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, Y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test_tensor)\n",
        "        _, predicted_val = torch.max(val_outputs, dim=1)\n",
        "        num_correct = (predicted_val == Y_test_tensor).sum().item()\n",
        "        accuracy = num_correct / Y_test_tensor.size(0) * 100\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wHL-3QqW1Nhv",
        "outputId": "db6ca0ea-9a0a-4973-de7a-978dcf3dd9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 1.5848, Accuracy: 56.04%\n",
            "Epoch [2/100], Loss: 1.5431, Accuracy: 61.50%\n",
            "Epoch [3/100], Loss: 1.4722, Accuracy: 66.09%\n",
            "Epoch [4/100], Loss: 1.1467, Accuracy: 48.68%\n",
            "Epoch [5/100], Loss: 1.1932, Accuracy: 47.96%\n",
            "Epoch [6/100], Loss: 1.1179, Accuracy: 63.52%\n",
            "Epoch [7/100], Loss: 0.8890, Accuracy: 65.69%\n",
            "Epoch [8/100], Loss: 0.8240, Accuracy: 65.59%\n",
            "Epoch [9/100], Loss: 0.7766, Accuracy: 65.87%\n",
            "Epoch [10/100], Loss: 0.7327, Accuracy: 61.88%\n",
            "Epoch [11/100], Loss: 0.7472, Accuracy: 61.03%\n",
            "Epoch [12/100], Loss: 0.7038, Accuracy: 63.15%\n",
            "Epoch [13/100], Loss: 0.6065, Accuracy: 64.58%\n",
            "Epoch [14/100], Loss: 0.5279, Accuracy: 64.97%\n",
            "Epoch [15/100], Loss: 0.4877, Accuracy: 65.12%\n",
            "Epoch [16/100], Loss: 0.4731, Accuracy: 65.09%\n",
            "Epoch [17/100], Loss: 0.4710, Accuracy: 64.95%\n",
            "Epoch [18/100], Loss: 0.4712, Accuracy: 64.74%\n",
            "Epoch [19/100], Loss: 0.4654, Accuracy: 64.44%\n",
            "Epoch [20/100], Loss: 0.4510, Accuracy: 64.13%\n",
            "Epoch [21/100], Loss: 0.4298, Accuracy: 64.14%\n",
            "Epoch [22/100], Loss: 0.4035, Accuracy: 64.61%\n",
            "Epoch [23/100], Loss: 0.3757, Accuracy: 64.81%\n",
            "Epoch [24/100], Loss: 0.3516, Accuracy: 64.92%\n",
            "Epoch [25/100], Loss: 0.3353, Accuracy: 64.77%\n",
            "Epoch [26/100], Loss: 0.3268, Accuracy: 64.64%\n",
            "Epoch [27/100], Loss: 0.3231, Accuracy: 64.45%\n",
            "Epoch [28/100], Loss: 0.3197, Accuracy: 64.44%\n",
            "Epoch [29/100], Loss: 0.3137, Accuracy: 64.16%\n",
            "Epoch [30/100], Loss: 0.3048, Accuracy: 64.13%\n",
            "Epoch [31/100], Loss: 0.2948, Accuracy: 63.96%\n",
            "Epoch [32/100], Loss: 0.2858, Accuracy: 63.66%\n",
            "Epoch [33/100], Loss: 0.2784, Accuracy: 63.55%\n",
            "Epoch [34/100], Loss: 0.2722, Accuracy: 63.36%\n",
            "Epoch [35/100], Loss: 0.2661, Accuracy: 63.26%\n",
            "Epoch [36/100], Loss: 0.2595, Accuracy: 63.40%\n",
            "Epoch [37/100], Loss: 0.2524, Accuracy: 63.24%\n",
            "Epoch [38/100], Loss: 0.2451, Accuracy: 63.38%\n",
            "Epoch [39/100], Loss: 0.2384, Accuracy: 63.55%\n",
            "Epoch [40/100], Loss: 0.2326, Accuracy: 63.46%\n",
            "Epoch [41/100], Loss: 0.2277, Accuracy: 63.41%\n",
            "Epoch [42/100], Loss: 0.2238, Accuracy: 63.29%\n",
            "Epoch [43/100], Loss: 0.2206, Accuracy: 63.18%\n",
            "Epoch [44/100], Loss: 0.2175, Accuracy: 63.07%\n",
            "Epoch [45/100], Loss: 0.2143, Accuracy: 62.88%\n",
            "Epoch [46/100], Loss: 0.2104, Accuracy: 62.69%\n",
            "Epoch [47/100], Loss: 0.2061, Accuracy: 62.62%\n",
            "Epoch [48/100], Loss: 0.2016, Accuracy: 62.63%\n",
            "Epoch [49/100], Loss: 0.1974, Accuracy: 62.82%\n",
            "Epoch [50/100], Loss: 0.1937, Accuracy: 62.85%\n",
            "Epoch [51/100], Loss: 0.1904, Accuracy: 62.82%\n",
            "Epoch [52/100], Loss: 0.1874, Accuracy: 62.77%\n",
            "Epoch [53/100], Loss: 0.1847, Accuracy: 62.79%\n",
            "Epoch [54/100], Loss: 0.1822, Accuracy: 62.90%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-75f52fa65f5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-5a2eb6ab1e70>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation du modèle"
      ],
      "metadata": {
        "id": "aL6K7xYGbAU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "cm = confusion_matrix(Y_test_tensor.numpy(), predicted.numpy())\n",
        "print(cm)\n",
        "report = classification_report(Y_test_tensor.numpy(), predicted.numpy())\n",
        "print(report)"
      ],
      "metadata": {
        "id": "44R8qvnnbAw3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}